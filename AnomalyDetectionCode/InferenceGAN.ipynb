{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.vision.gan import *\n",
    "import torch\n",
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('datasetBenignas/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathI = path/'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(bs:int, size:int):\n",
    "  \"Generates two `GAN` DataLoaders\"\n",
    "  dblock = DataBlock(blocks=(ImageBlock, ImageBlock),\n",
    "                   get_items=get_image_files,\n",
    "                   get_y = lambda x: pathI/x.name,\n",
    "                   splitter=RandomSplitter(),\n",
    "                   item_tfms=Resize(size),\n",
    "                   batch_tfms=[*aug_transforms(max_zoom=2.),\n",
    "                               Normalize.from_stats(*imagenet_stats)])\n",
    "  dls = dblock.dataloaders(pathI, bs=bs, path=path)\n",
    "  dls.c = 3 # For 3 channel image\n",
    "  return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_gen = get_dls(64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbone = resnet34\n",
    "\n",
    "def create_gen_learner():\n",
    "  return unet_learner(dls_gen, bbone, loss_func=loss_gen,blur=True, norm_type=NormType.Weight, self_attention=True,\n",
    "                  y_range=y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd, y_range, loss_gen = 1e-3, (-3., 3.), MSELossFlat()\n",
    "learn_gen = create_gen_learner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_gen = 'image_gen'\n",
    "path_gen = path/name_gen\n",
    "path_gen.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_g = get_image_files(path/name_gen)\n",
    "path_i = get_image_files(path/'images')\n",
    "fnames = path_g + path_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crit_dls(fnames, bs:int, size:int):\n",
    "  \"Generate two `Critic` DataLoaders\"\n",
    "  splits = RandomSplitter(0.1)(fnames)\n",
    "  dsrc = Datasets(fnames, tfms=[[PILImage.create], [parent_label, Categorize]],\n",
    "                 splits=splits)\n",
    "  tfms = [ToTensor(), Resize(size)]\n",
    "  gpu_tfms = [IntToFloatTensor(), Normalize.from_stats(*imagenet_stats)]\n",
    "  return dsrc.dataloaders(bs=bs, after_item=tfms, after_batch=gpu_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_crit = get_crit_dls(fnames, bs=64, size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_crit = AdaptiveLoss(nn.BCEWithLogitsLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crit_learner(dls, metrics):\n",
    "  return Learner(dls, gan_critic(), metrics=metrics, loss_func=loss_crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_crit = create_crit_learner(dls_crit, accuracy_thresh_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_crit = get_crit_dls(fnames, bs=64, size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_crit = create_crit_learner(dls_crit, metrics=None).load('critic-pre2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen = create_gen_learner().load('gen-pre2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANDiscriminativeLR(Callback):\n",
    "    \"`Callback` that handles multiplying the learning rate by `mult_lr` for the critic.\"\n",
    "    def __init__(self, mult_lr=5.): self.mult_lr = mult_lr\n",
    "\n",
    "    def begin_batch(self):\n",
    "        \"Multiply the current lr if necessary.\"\n",
    "        if not self.learn.gan_trainer.gen_mode and self.training: \n",
    "            self.learn.opt.set_hyper('lr', learn.opt.hypers[0]['lr']*self.mult_lr)\n",
    "\n",
    "    def after_batch(self):\n",
    "        \"Put the LR back to its value if necessary.\"\n",
    "        if not self.learn.gan_trainer.gen_mode: self.learn.opt.set_hyper('lr', learn.opt.hypers[0]['lr']/self.mult_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "switcher = AdaptiveGANSwitcher(critic_thresh=.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = GANLearner.from_learners(learn_gen, learn_crit, weights_gen=(1.,50.), show_img=False, switcher=switcher,\n",
    "                                 opt_func=partial(Adam, mom=0.), cbs=GANDiscriminativeLR(mult_lr=5.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.vision.gan.GANLearner at 0x7fd9f25957b8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#3) [0.6588068008422852,0.6588068008422852,0.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "learn.export('anomalydetector.pkl',pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn1 = load_learner('anomalydetector.pkl',pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/.virtualenvs/segmentation/lib/python3.6/site-packages/fastai/callback/core.py:51: UserWarning: You are shadowing an attribute (generator) that exists in the learner. Use `self.learn.generator` to avoid this\n",
      "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n",
      "/home/jonathan/.virtualenvs/segmentation/lib/python3.6/site-packages/fastai/callback/core.py:51: UserWarning: You are shadowing an attribute (critic) that exists in the learner. Use `self.learn.critic` to avoid this\n",
      "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n",
      "/home/jonathan/.virtualenvs/segmentation/lib/python3.6/site-packages/fastai/callback/core.py:51: UserWarning: You are shadowing an attribute (gen_mode) that exists in the learner. Use `self.learn.gen_mode` to avoid this\n",
      "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(TensorImage([[[135, 132, 130,  ..., 186, 197, 196],\n",
       "          [136, 133, 133,  ..., 186, 193, 195],\n",
       "          [132, 131, 134,  ..., 188, 182, 187],\n",
       "          ...,\n",
       "          [201, 196, 193,  ..., 227, 231, 235],\n",
       "          [204, 203, 197,  ..., 235, 231, 237],\n",
       "          [202, 207, 198,  ..., 241, 239, 239]],\n",
       " \n",
       "         [[107, 107, 109,  ..., 145, 150, 152],\n",
       "          [106, 107, 111,  ..., 140, 143, 149],\n",
       "          [111, 114, 106,  ..., 135, 144, 148],\n",
       "          ...,\n",
       "          [164, 160, 160,  ..., 236, 236, 237],\n",
       "          [166, 162, 163,  ..., 237, 234, 236],\n",
       "          [166, 165, 166,  ..., 244, 240, 241]],\n",
       " \n",
       "         [[132, 135, 130,  ..., 143, 144, 144],\n",
       "          [135, 138, 138,  ..., 145, 141, 142],\n",
       "          [143, 144, 137,  ..., 132, 145, 147],\n",
       "          ...,\n",
       "          [176, 172, 172,  ..., 236, 239, 238],\n",
       "          [178, 178, 171,  ..., 238, 237, 238],\n",
       "          [177, 180, 169,  ..., 239, 241, 240]]]),\n",
       " TensorBase([[[ 0.2036,  0.1547,  0.1176,  ...,  1.0768,  1.2576,  1.2415],\n",
       "          [ 0.2213,  0.1708,  0.1697,  ...,  1.0687,  1.2007,  1.2244],\n",
       "          [ 0.1431,  0.1349,  0.1884,  ...,  1.1066,  1.0063,  1.0946],\n",
       "          ...,\n",
       "          [ 1.3371,  1.2514,  1.1885,  ...,  1.7726,  1.8517,  1.9083],\n",
       "          [ 1.3863,  1.3598,  1.2702,  ...,  1.9130,  1.8522,  1.9529],\n",
       "          [ 1.3444,  1.4332,  1.2820,  ...,  2.0132,  1.9763,  1.9824]],\n",
       " \n",
       "         [[-0.1564, -0.1471, -0.1134,  ...,  0.5032,  0.5934,  0.6288],\n",
       "          [-0.1718, -0.1563, -0.0751,  ...,  0.4210,  0.4828,  0.5818],\n",
       "          [-0.0820, -0.0261, -0.1638,  ...,  0.3395,  0.4914,  0.5590],\n",
       "          ...,\n",
       "          [ 0.8414,  0.7665,  0.7659,  ...,  2.1075,  2.1094,  2.1274],\n",
       "          [ 0.8716,  0.8141,  0.8196,  ...,  2.1163,  2.0750,  2.1115],\n",
       "          [ 0.8746,  0.8683,  0.8718,  ...,  2.2407,  2.1817,  2.1851]],\n",
       " \n",
       "         [[ 0.4963,  0.5536,  0.4704,  ...,  0.7036,  0.7149,  0.7068],\n",
       "          [ 0.5542,  0.6110,  0.6014,  ...,  0.7381,  0.6583,  0.6818],\n",
       "          [ 0.6958,  0.7080,  0.5973,  ...,  0.5104,  0.7264,  0.7585],\n",
       "          ...,\n",
       "          [ 1.2678,  1.2047,  1.2027,  ...,  2.3159,  2.3663,  2.3569],\n",
       "          [ 1.2987,  1.3065,  1.1870,  ...,  2.3598,  2.3296,  2.3535],\n",
       "          [ 1.2839,  1.3493,  1.1531,  ...,  2.3656,  2.4103,  2.3927]]]),\n",
       " TensorBase([[[ 0.2036,  0.1547,  0.1176,  ...,  1.0768,  1.2576,  1.2415],\n",
       "          [ 0.2213,  0.1708,  0.1697,  ...,  1.0687,  1.2007,  1.2244],\n",
       "          [ 0.1431,  0.1349,  0.1884,  ...,  1.1066,  1.0063,  1.0946],\n",
       "          ...,\n",
       "          [ 1.3371,  1.2514,  1.1885,  ...,  1.7726,  1.8517,  1.9083],\n",
       "          [ 1.3863,  1.3598,  1.2702,  ...,  1.9130,  1.8522,  1.9529],\n",
       "          [ 1.3444,  1.4332,  1.2820,  ...,  2.0132,  1.9763,  1.9824]],\n",
       " \n",
       "         [[-0.1564, -0.1471, -0.1134,  ...,  0.5032,  0.5934,  0.6288],\n",
       "          [-0.1718, -0.1563, -0.0751,  ...,  0.4210,  0.4828,  0.5818],\n",
       "          [-0.0820, -0.0261, -0.1638,  ...,  0.3395,  0.4914,  0.5590],\n",
       "          ...,\n",
       "          [ 0.8414,  0.7665,  0.7659,  ...,  2.1075,  2.1094,  2.1274],\n",
       "          [ 0.8716,  0.8141,  0.8196,  ...,  2.1163,  2.0750,  2.1115],\n",
       "          [ 0.8746,  0.8683,  0.8718,  ...,  2.2407,  2.1817,  2.1851]],\n",
       " \n",
       "         [[ 0.4963,  0.5536,  0.4704,  ...,  0.7036,  0.7149,  0.7068],\n",
       "          [ 0.5542,  0.6110,  0.6014,  ...,  0.7381,  0.6583,  0.6818],\n",
       "          [ 0.6958,  0.7080,  0.5973,  ...,  0.5104,  0.7264,  0.7585],\n",
       "          ...,\n",
       "          [ 1.2678,  1.2047,  1.2027,  ...,  2.3159,  2.3663,  2.3569],\n",
       "          [ 1.2987,  1.3065,  1.1870,  ...,  2.3598,  2.3296,  2.3535],\n",
       "          [ 1.2839,  1.3493,  1.1531,  ...,  2.3656,  2.4103,  2.3927]]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('datasetMalignasTest/1005124.tif - Series 3_roi_0002-0049.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0041958676"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array((preds[0][0]-preds[1][0])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33689\r\n"
     ]
    }
   ],
   "source": [
    "!ls datasetBenignas/images | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlTrain = dls_gen.train.new(shuffle=False, drop_last=False, \n",
    "                       after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])\n",
    "dlValid = dls_gen.valid.new(shuffle=False, drop_last=False, \n",
    "                       after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6737"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dlValid.dataset.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/.virtualenvs/segmentation/lib/python3.6/site-packages/fastai/callback/core.py:51: UserWarning: You are shadowing an attribute (generator) that exists in the learner. Use `self.learn.generator` to avoid this\n",
      "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n",
      "/home/jonathan/.virtualenvs/segmentation/lib/python3.6/site-packages/fastai/callback/core.py:51: UserWarning: You are shadowing an attribute (critic) that exists in the learner. Use `self.learn.critic` to avoid this\n",
      "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n",
      "/home/jonathan/.virtualenvs/segmentation/lib/python3.6/site-packages/fastai/callback/core.py:51: UserWarning: You are shadowing an attribute (gen_mode) that exists in the learner. Use `self.learn.gen_mode` to avoid this\n",
      "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Computing error for training dataset\n",
    "errors = []\n",
    "preds,real = learn.get_preds(dl=dlTrain)\n",
    "\n",
    "\n",
    "for (image, recon) in zip(real, preds):\n",
    "    # compute the mean squared error between the ground-truth image\n",
    "    # and the reconstructed image, then add it to our list of errors\n",
    "    mse = np.mean(np.array((image - recon) ** 2))\n",
    "    errors.append(mse)\n",
    "    \n",
    "preds,real = learn.get_preds(dl=dlValid)\n",
    "\n",
    "for (image, recon) in zip(real, preds):\n",
    "    # compute the mean squared error between the ground-truth image\n",
    "    # and the reconstructed image, then add it to our list of errors\n",
    "    mse = np.mean(np.array((image - recon) ** 2))\n",
    "    errors.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = np.quantile(errors, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04763923677802065"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the errors of benign images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathI = Path('datasetBenignasTest/')\n",
    "dblock = DataBlock(blocks=(ImageBlock, ImageBlock),\n",
    "               get_items=get_image_files,\n",
    "               get_y = lambda x: pathI/x.name,\n",
    "               splitter=RandomSplitter(),\n",
    "               item_tfms=Resize(64),\n",
    "               batch_tfms=[*aug_transforms(max_zoom=2.),\n",
    "                           Normalize.from_stats(*imagenet_stats)])\n",
    "dls_gen = dblock.dataloaders(pathI, bs=128, path=path)\n",
    "dls_gen.c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlTrain = dls_gen.train.new(shuffle=False, drop_last=False, \n",
    "                       after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])\n",
    "dlValid = dls_gen.valid.new(shuffle=False, drop_last=False, \n",
    "                       after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Computing error for training dataset\n",
    "errorsBenign = []\n",
    "preds,real = learn.get_preds(dl=dlTrain)\n",
    "\n",
    "\n",
    "for (image, recon) in zip(real, preds):\n",
    "    # compute the mean squared error between the ground-truth image\n",
    "    # and the reconstructed image, then add it to our list of errors\n",
    "    mse = np.mean(np.array((image - recon) ** 2))\n",
    "    errorsBenign.append(mse)\n",
    "    \n",
    "preds,real = learn.get_preds(dl=dlValid)\n",
    "\n",
    "for (image, recon) in zip(real, preds):\n",
    "    # compute the mean squared error between the ground-truth image\n",
    "    # and the reconstructed image, then add it to our list of errors\n",
    "    mse = np.mean(np.array((image - recon) ** 2))\n",
    "    errorsBenign.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.where(np.array(errorsBenign) >= thresh)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  633,   943,  1288,  1358,  1781,  2733,  5519,  5747,  7884,\n",
       "        8090,  8652,  8994,  9305,  9594, 10189, 10233, 11542, 11805,\n",
       "       12160])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "benignas = dlTrain.dataset.items + dlValid.dataset.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for idx in idxs:\n",
    "    res.append([benignas[idx],errorsBenign[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the errors of benign images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathI = Path('datasetMalignasTest/')\n",
    "dblock = DataBlock(blocks=(ImageBlock, ImageBlock),\n",
    "               get_items=get_image_files,\n",
    "               get_y = lambda x: pathI/x.name,\n",
    "               splitter=RandomSplitter(),\n",
    "               item_tfms=Resize(64),\n",
    "               batch_tfms=[*aug_transforms(max_zoom=2.),\n",
    "                           Normalize.from_stats(*imagenet_stats)])\n",
    "dls_gen = dblock.dataloaders(pathI, bs=128, path=path)\n",
    "dls_gen.c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlTrain = dls_gen.train.new(shuffle=False, drop_last=False, \n",
    "                       after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])\n",
    "dlValid = dls_gen.valid.new(shuffle=False, drop_last=False, \n",
    "                       after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Computing error for training dataset\n",
    "errorsMalign = []\n",
    "preds,real = learn.get_preds(dl=dlTrain)\n",
    "\n",
    "\n",
    "for (image, recon) in zip(real, preds):\n",
    "    # compute the mean squared error between the ground-truth image\n",
    "    # and the reconstructed image, then add it to our list of errors\n",
    "    mse = np.mean(np.array((image - recon) ** 2))\n",
    "    errorsMalign.append(mse)\n",
    "    \n",
    "preds,real = learn.get_preds(dl=dlValid)\n",
    "\n",
    "for (image, recon) in zip(real, preds):\n",
    "    # compute the mean squared error between the ground-truth image\n",
    "    # and the reconstructed image, then add it to our list of errors\n",
    "    mse = np.mean(np.array((image - recon) ** 2))\n",
    "    errorsMalign.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.where(np.array(errorsMalign) >= thresh)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "malignas = dlTrain.dataset.items + dlValid.dataset.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idxs:\n",
    "    res.append([malignas[idx],errorsMalign[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res,columns=['name','error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractName(string):\n",
    "    return string[string.find('/')+1:string.find(' - ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['imageName'] = df['name'].apply(lambda x: extractName(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imageName\n",
       "1005124.tif     165\n",
       "1005125.tif     549\n",
       "1005126.tif     805\n",
       "1005127.tif    1217\n",
       "1005128.tif    3272\n",
       "1005129.tif    2149\n",
       "1005130.tif    1103\n",
       "1005131.tif      13\n",
       "1005132.tif     355\n",
       "1005133.tif      86\n",
       "1005134.tif      14\n",
       "1005205.tif      32\n",
       "1005206.tif     681\n",
       "1005207.tif     151\n",
       "1005208.tif       3\n",
       "1005209.tif     220\n",
       "1005210.tif     145\n",
       "1005211.tif     128\n",
       "1005212.tif      33\n",
       "14I.tif           1\n",
       "20I.tif           8\n",
       "75I.tif          10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('imageName').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>error</th>\n",
       "      <th>imageName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasetBenignasTest/75I.tif - Series 3_roi_667...</td>\n",
       "      <td>0.071940</td>\n",
       "      <td>75I.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasetBenignasTest/75I.tif - Series 3_roi_266...</td>\n",
       "      <td>0.066904</td>\n",
       "      <td>75I.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasetBenignasTest/75I.tif - Series 3_roi_053...</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>75I.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasetBenignasTest/75I.tif - Series 3_roi_438...</td>\n",
       "      <td>0.084209</td>\n",
       "      <td>75I.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>datasetBenignasTest/75I.tif - Series 3_roi_517...</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>75I.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>datasetBenignasTest/75I.tif - Series 3_roi_425...</td>\n",
       "      <td>0.056597</td>\n",
       "      <td>75I.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>datasetBenignasTest/75I.tif - Series 3_roi_003...</td>\n",
       "      <td>0.062762</td>\n",
       "      <td>75I.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>datasetBenignasTest/75I.tif - Series 3_roi_415...</td>\n",
       "      <td>0.058255</td>\n",
       "      <td>75I.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>datasetBenignasTest/75I.tif - Series 3_roi_375...</td>\n",
       "      <td>0.053862</td>\n",
       "      <td>75I.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>datasetBenignasTest/75I.tif - Series 3_roi_068...</td>\n",
       "      <td>0.047645</td>\n",
       "      <td>75I.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name     error imageName\n",
       "0   datasetBenignasTest/75I.tif - Series 3_roi_667...  0.071940   75I.tif\n",
       "2   datasetBenignasTest/75I.tif - Series 3_roi_266...  0.066904   75I.tif\n",
       "3   datasetBenignasTest/75I.tif - Series 3_roi_053...  0.048802   75I.tif\n",
       "4   datasetBenignasTest/75I.tif - Series 3_roi_438...  0.084209   75I.tif\n",
       "7   datasetBenignasTest/75I.tif - Series 3_roi_517...  0.051724   75I.tif\n",
       "10  datasetBenignasTest/75I.tif - Series 3_roi_425...  0.056597   75I.tif\n",
       "11  datasetBenignasTest/75I.tif - Series 3_roi_003...  0.062762   75I.tif\n",
       "15  datasetBenignasTest/75I.tif - Series 3_roi_415...  0.058255   75I.tif\n",
       "16  datasetBenignasTest/75I.tif - Series 3_roi_375...  0.053862   75I.tif\n",
       "17  datasetBenignasTest/75I.tif - Series 3_roi_068...  0.047645   75I.tif"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.imageName=='75I.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otros thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh = 0.047\n",
    "# idxsBenign = np.where(np.array(errorsBenign) >= thresh)[0]\n",
    "# idxsMalign = np.where(np.array(errorsMalign) >= thresh)[0]\n",
    "\n",
    "# res = []\n",
    "# for idx in idxsBenign:\n",
    "#     res.append([benignas[idx],errorsBenign[idx]])\n",
    "# for idx in idxsMalign:\n",
    "#     res.append([malignas[idx],errorsMalign[idx]])\n",
    "    \n",
    "# df = pd.DataFrame(res,columns=['name','error'])\n",
    "# df['imageName'] = df['name'].apply(lambda x: extractName(str(x)))\n",
    "# df.groupby('imageName').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasetMalignasTest/1005208.tif - Series 3_roi_3991-1154.tif\n",
      "datasetMalignasTest/1005208.tif - Series 3_roi_3885-1360.tif\n",
      "datasetMalignasTest/1005208.tif - Series 3_roi_0852-1446.tif\n"
     ]
    }
   ],
   "source": [
    "for x in df[df.imageName=='1005208.tif'].name:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
